import pandas as pd
import numpy as np
import joblib
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import accuracy_score

# Load dataset
data = pd.read_csv("network_vulnerability_dataset .csv")

# Convert Open Ports from list to count
data["Open Ports"] = data["Open Ports"].apply(lambda x: len(eval(x)) if isinstance(x, str) else len(x))

# Normalize Open Ports column
scaler = StandardScaler()
data["Open Ports"] = scaler.fit_transform(data[["Open Ports"]])

# Encode categorical features
label_encoders = {}
categorical_features = ["Encryption", "WPS Status"]

for feature in categorical_features:
    encoder = LabelEncoder()
    data[feature] = data[feature].astype(str)
    data[feature] = encoder.fit_transform(data[feature])
    label_encoders[feature] = encoder

# Encode target variable
target_encoder = LabelEncoder()
data["Attack Type"] = target_encoder.fit_transform(data["Attack Type"].astype(str))

# Split dataset into training and testing features
X = data.drop(columns=["Attack Type"])
y = data["Attack Type"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Train models
rf_model = RandomForestClassifier(n_estimators=500, max_depth=15, min_samples_split=4, random_state=42)
rf_model.fit(X_train, y_train)

xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', max_depth=12, learning_rate=0.08, n_estimators=500)
xgb_model.fit(X_train, y_train)

# Ensemble model prediction
rf_predictions = rf_model.predict_proba(X_test)
xgb_predictions = xgb_model.predict_proba(X_test)
final_predictions = np.argmax((rf_predictions * 0.6 + xgb_predictions * 0.4), axis=1)

# Evaluate accuracy
rf_accuracy = accuracy_score(y_test, np.argmax(rf_predictions, axis=1)) * 100
xgb_accuracy = accuracy_score(y_test, np.argmax(xgb_predictions, axis=1)) * 100
ensemble_accuracy = accuracy_score(y_test, final_predictions) * 100

print(f"✅ RandomForest Accuracy: {rf_accuracy:.2f}%")
print(f"✅ XGBoost Accuracy: {xgb_accuracy:.2f}%")
print(f"✅ Ensemble Model Accuracy: {ensemble_accuracy:.2f}%")

# Save models and encoders
joblib.dump(rf_model, "rf_model.pkl")
joblib.dump(xgb_model, "xgb_model.pkl")
joblib.dump(label_encoders, "label_encoders.pkl")
joblib.dump(target_encoder, "target_encoder.pkl")
joblib.dump(scaler, "scaler.pkl")

print("✅ Model training complete. Model and encoders saved.")
